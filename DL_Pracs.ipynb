{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO49hbQas964eAqBCaccQZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riteshdurgiani/DLPracs/blob/main/DL_Pracs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# McCulloch Pitts\n"
      ],
      "metadata": {
        "id": "pb6sEG84cq1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "dNY-O9mjlqmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeMatrix(arr,n):\n",
        "  l = []\n",
        "  for i in range(0,n):\n",
        "    l.append(arr[i])\n",
        "  matrix.append(l)\n",
        "\n",
        "def generateAllBinaryStrings(n,arr,i):\n",
        "  if i == n:\n",
        "    makeMatrix(arr,n)\n",
        "    return \n",
        "  arr[i] = 0\n",
        "  generateAllBinaryStrings(n,arr,i+1)\n",
        "\n",
        "  arr[i] = 1\n",
        "  generateAllBinaryStrings(n,arr,i+1)\n",
        "\n"
      ],
      "metadata": {
        "id": "SAlmzQp5cvaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AND GATE \n",
        "col = int(input(\"Enter the number of inputs\"))\n",
        "row = pow(2,col) \n",
        "\n",
        "arr = [None] * col\n",
        "matrix = [[]]\n",
        "generateAllBinaryStrings(col,arr,0)\n",
        "\n",
        "print()\n",
        "\n",
        "W = np.ones((col,) , dtype='int')\n",
        "\n",
        "for i in range(1,row+1):\n",
        "  sum = 0\n",
        "  for j in range(col):\n",
        "    sum += matrix[i][j] * W[j]\n",
        "  if sum >= col:\n",
        "    for r in range(col):\n",
        "      print(matrix[i][r],end =' ')\n",
        "    print(1)\n",
        "  else:\n",
        "    for r in range(col):\n",
        "      print(matrix[i][r],end=' ')\n",
        "    print(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9F80N0Qc2jp",
        "outputId": "bdc2d163-3e90-4cd7-c65b-c898c0022244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of inputs3\n",
            "\n",
            "0 0 0 0\n",
            "0 0 1 0\n",
            "0 1 0 0\n",
            "0 1 1 0\n",
            "1 0 0 0\n",
            "1 0 1 0\n",
            "1 1 0 0\n",
            "1 1 1 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NAND GATE  \n",
        "col = int(input(\"Enter the number of inputs\"))\n",
        "row = pow(2,col) \n",
        "\n",
        "arr = [None] * col\n",
        "matrix = [[]]\n",
        "generateAllBinaryStrings(col,arr,0)\n",
        "\n",
        "print()\n",
        "\n",
        "W = -1*(np.ones((col,) , dtype='int'))\n",
        "\n",
        "for i in range(1,row+1):\n",
        "  sum = 0\n",
        "  for j in range(col):\n",
        "    sum += matrix[i][j] * W[j]\n",
        "  if sum >= -(col-1):\n",
        "    for r in range(col):\n",
        "      print(matrix[i][r],end =' ')\n",
        "    print(1)\n",
        "  else:\n",
        "    for r in range(col):\n",
        "      print(matrix[i][r],end=' ')\n",
        "    print(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_uTNBRCoCGx",
        "outputId": "fc249232-b204-497a-c61e-67aa38021564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of inputs3\n",
            "\n",
            "0 0 0 1\n",
            "0 0 1 1\n",
            "0 1 0 1\n",
            "0 1 1 1\n",
            "1 0 0 1\n",
            "1 0 1 1\n",
            "1 1 0 1\n",
            "1 1 1 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NOR GATE \n",
        "col = int(input(\"Enter the number of inputs\"))\n",
        "row = pow(2,col) \n",
        "\n",
        "arr = [None] * col\n",
        "matrix = [[]]\n",
        "generateAllBinaryStrings(col,arr,0)\n",
        "\n",
        "print()\n",
        "\n",
        "W = -1*(np.ones((col,) , dtype='int'))\n",
        "\n",
        "for i in range(1,row+1):\n",
        "  sum = 0\n",
        "  for j in range(col):\n",
        "    sum += matrix[i][j] * W[j]\n",
        "  if sum >= 0:\n",
        "    for r in range(col):\n",
        "      print(matrix[i][r],end =' ')\n",
        "    print(1)\n",
        "  else:\n",
        "    for r in range(col):\n",
        "      print(matrix[i][r],end=' ')\n",
        "    print(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jLfissRo6HI",
        "outputId": "10df2205-b6d3-48be-e46a-3b67464969ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of inputs3\n",
            "\n",
            "0 0 0 1\n",
            "0 0 1 0\n",
            "0 1 0 0\n",
            "0 1 1 0\n",
            "1 0 0 0\n",
            "1 0 1 0\n",
            "1 1 0 0\n",
            "1 1 1 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NOT \n",
        "\n",
        "x = [0,1]\n",
        "w = -1\n",
        "t = 0\n",
        "\n",
        "for i in range(len(x)):\n",
        "  if x[i]*w >= t:\n",
        "    print(\"~\",x[i],\":\",1)\n",
        "  else:\n",
        "    print(\"~\",x[i],\":\",0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zG7X3P-pQs4",
        "outputId": "effde913-9ba6-4bed-cad7-120178d671d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~ 0 : 1\n",
            "~ 1 : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PERCEPTRON"
      ],
      "metadata": {
        "id": "CMqjNnJ5rzmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discrete**"
      ],
      "metadata": {
        "id": "ag8rVOpKcUsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import itertools\n",
        "def unipolar(result):\n",
        "  return 1 if(result >=0) else 0\n",
        "def bipolar(result):\n",
        "  return 1 if(result >=0) else -1\n",
        "def predictt(X,weights,type):\n",
        "  result = np.dot(X,weights)\n",
        "  if type == \"unipolar\":\n",
        "    return unipolar(result)\n",
        "  else:\n",
        "    return bipolar(result)\n",
        "def train(X,y,weights,type,epochs = 500,c=0.5):\n",
        "  for epoch in range(epochs):\n",
        "    loss = 0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predictt(Xi,weights,type)\n",
        "      r = yi - y_pred\n",
        "      loss += abs(r)\n",
        "      delta_w = c*r*Xi\n",
        "      weights += delta_w\n",
        "    print(f'Weights after epoch {epoch} : ',weights)\n",
        "    if loss == 0:\n",
        "      break\n",
        "  print('Learned Weights : ',weights)\n",
        "  weights = weights.reshape((n+1,1))\n",
        "  test(X,y,weights,type)\n",
        "def test(X,y,learned_weights,type):\n",
        "  results = np.dot(X,learned_weights).flatten()\n",
        "  print(\"Actual Values : \",y)\n",
        "  if type == \"unipolar\":\n",
        "    y_pred = np.array([1 if result >=0 else 0 for result in results ])\n",
        "    print('Predicted Values : ', y_pred)\n",
        "  if type == \"bipolar\":\n",
        "    y_pred = np.array([1 if result >=0 else -1 for result in results ])\n",
        "    print('Predicted Values : ', y_pred)\n",
        "n = int(input(\"enter number of bits  \"))\n",
        "X = np.array([list(i) + [1] for i in itertools.product([0,1],repeat = n)])\n",
        "weights = input(f'Enter {n} initial weights and 1 bias : ')\n",
        "weights = np.array([float(weight) for weight in weights.split()],dtype='longdouble')\n",
        "\n",
        "print()\n",
        "\n",
        "#AND GATE \n",
        "print('---- AND GATE USING PERCEPTRON ----')\n",
        "y = np.array([0] * (2**n))\n",
        "y[-1] = 1\n",
        "train(X,y,weights.copy(),'unipolar')\n",
        "\n",
        "print('---- OR GATE USING PERCEPTRON ----')\n",
        "y = np.array([1]*(2**n))\n",
        "y[0] = 0\n",
        "train(X, y, weights.copy(), 'unipolar')\n",
        "print()\n",
        "print()\n",
        "\n",
        "# 3) NOR GATE UNIPOLAR\n",
        "print('---- NOR GATE USING PERCEPTRON ----')\n",
        "y = np.array([0]*(2**n))\n",
        "y[0] = 1\n",
        "train(X, y, weights.copy(), 'unipolar')\n",
        "print()\n",
        "print()\n",
        "\n",
        "# 4) NAND GATE UNIPOLAR\n",
        "print('---- NAND GATE USING PERCEPTRON ----')\n",
        "y = np.array([1]*(2**n))\n",
        "y[-1] = 0\n",
        "train(X, y, weights.copy(), 'unipolar')\n",
        "print()\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWoRB_pkcYPj",
        "outputId": "1e3b4eb7-963a-4f13-d82b-553bdc10527f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter number of bits  3\n",
            "Enter 3 initial weights and 1 bias : 1 1 1 0\n",
            "\n",
            "---- AND GATE USING PERCEPTRON ----\n",
            "Weights after epoch 0 :  [ 1.   1.   0.5 -1.5]\n",
            "Weights after epoch 1 :  [ 1.5  1.   0.5 -1.5]\n",
            "Weights after epoch 2 :  [ 1.5  0.5  0.5 -2. ]\n",
            "Weights after epoch 3 :  [ 1.5  1.   0.5 -2. ]\n",
            "Weights after epoch 4 :  [ 1.5  1.5  0.5 -2. ]\n",
            "Weights after epoch 5 :  [ 1.5  1.   0.5 -2.5]\n",
            "Weights after epoch 6 :  [ 1.5  1.   1.  -2.5]\n",
            "Weights after epoch 7 :  [ 1.5  1.5  1.  -2.5]\n",
            "Weights after epoch 8 :  [ 1.5  1.   0.5 -3. ]\n",
            "Weights after epoch 9 :  [ 1.5  1.   0.5 -3. ]\n",
            "Learned Weights :  [ 1.5  1.   0.5 -3. ]\n",
            "Actual Values :  [0 0 0 0 0 0 0 1]\n",
            "Predicted Values :  [0 0 0 0 0 0 0 1]\n",
            "---- OR GATE USING PERCEPTRON ----\n",
            "Weights after epoch 0 :  [ 1.   1.   1.  -0.5]\n",
            "Weights after epoch 1 :  [ 1.   1.   1.  -0.5]\n",
            "Learned Weights :  [ 1.   1.   1.  -0.5]\n",
            "Actual Values :  [0 1 1 1 1 1 1 1]\n",
            "Predicted Values :  [0 1 1 1 1 1 1 1]\n",
            "\n",
            "\n",
            "---- NOR GATE USING PERCEPTRON ----\n",
            "Weights after epoch 0 :  [ 1.   0.   0.  -1.5]\n",
            "Weights after epoch 1 :  [ 0.5  0.   0.  -1.5]\n",
            "Weights after epoch 2 :  [ 0.5  0.   0.  -1. ]\n",
            "Weights after epoch 3 :  [ 0.  0.  0. -1.]\n",
            "Weights after epoch 4 :  [ 0.   0.   0.  -0.5]\n",
            "Weights after epoch 5 :  [ 0.   0.  -0.5 -0.5]\n",
            "Weights after epoch 6 :  [ 0.  -0.5 -0.5 -0.5]\n",
            "Weights after epoch 7 :  [-0.5 -0.5 -0.5 -0.5]\n",
            "Weights after epoch 8 :  [-0.5 -0.5 -0.5  0. ]\n",
            "Weights after epoch 9 :  [-0.5 -0.5 -0.5  0. ]\n",
            "Learned Weights :  [-0.5 -0.5 -0.5  0. ]\n",
            "Actual Values :  [1 0 0 0 0 0 0 0]\n",
            "Predicted Values :  [1 0 0 0 0 0 0 0]\n",
            "\n",
            "\n",
            "---- NAND GATE USING PERCEPTRON ----\n",
            "Weights after epoch 0 :  [ 0.5  0.5  0.5 -0.5]\n",
            "Weights after epoch 1 :  [ 0.   0.   0.  -0.5]\n",
            "Weights after epoch 2 :  [-0.5 -0.5 -0.5 -0.5]\n",
            "Weights after epoch 3 :  [-0.5 -0.5 -0.5  0.5]\n",
            "Weights after epoch 4 :  [-1.  -0.5 -0.5  0.5]\n",
            "Weights after epoch 5 :  [-1.5 -0.5 -0.5  0.5]\n",
            "Weights after epoch 6 :  [-1.5 -0.5 -0.5  1. ]\n",
            "Weights after epoch 7 :  [-1.  -0.5 -0.5  1.5]\n",
            "Weights after epoch 8 :  [-1.  -0.5 -0.5  1.5]\n",
            "Learned Weights :  [-1.  -0.5 -0.5  1.5]\n",
            "Actual Values :  [1 1 1 1 1 1 1 0]\n",
            "Predicted Values :  [1 1 1 1 1 1 1 0]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continuous**"
      ],
      "metadata": {
        "id": "beMvnGangUlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#only activation function changes for continuous that is as follows :\n",
        "def bipolar_activation(net, lambdaa = 1):\n",
        "    return (2/(1+np.exp(-lambdaa*net))) - 1\n",
        "\n",
        "def unipolar_activation(net, lambdaa = 0.3):\n",
        "    return (1/(1+np.exp(-lambdaa*net)))"
      ],
      "metadata": {
        "id": "B3o5m1vqgNEw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Momentum based gradient descent (vanilla)"
      ],
      "metadata": {
        "id": "guZ6b3a9r3hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def predict(X,weights,l=1):\n",
        "  result = np.dot(X,weights)\n",
        "  return (1/(1+np.exp(-l * result)))\n",
        "def calculate_derivate(X,y,y_pred):\n",
        "  return ((y_pred - y) * (y_pred) * (1-y_pred) * X)\n",
        "def calculate_error(y,y_pred):\n",
        "  return np.square(y_pred - y)\n",
        "def momentum_vanilla_gradient_descent(X,y,weights,epochs=1000,learning_rate=0.01,gamma = 0.9):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    dw =0\n",
        "    error = 0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      error += calculate_error(yi,y_pred)\n",
        "\n",
        "    velocity = (gamma*velocity) + (learning_rate * dw)\n",
        "    \n",
        "    weights -= velocity\n",
        "    \n",
        "    error /= (2*len(X))\n",
        "\n",
        "    if(epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} :',weights)\n",
        "      print(f'Error after epoch {epoch+1} :',error)\n",
        "\n",
        "def momentum_stochastic_gradient_descent(X,y,weights,epochs=1000,learning_rate=0.01,gamma = 0.9):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    \n",
        "    error = 0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw = calculate_derivate(Xi,yi,y_pred)\n",
        "      error += calculate_error(yi,y_pred)\n",
        "\n",
        "      velocity = (gamma*velocity) + (learning_rate * dw)\n",
        "      \n",
        "      weights -= velocity\n",
        "      \n",
        "    error /= (2*len(X))\n",
        "\n",
        "    if(epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} :',weights)\n",
        "      print(f'Error after epoch {epoch+1} :',error)\n",
        "\n",
        "def momentum_minibatch_gradient_descent(X,y,weights,epochs=1000,learning_rate=0.01,gamma = 0.9,batch=2):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    dw =0\n",
        "    error = 0\n",
        "    i=0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      i += 1\n",
        "      error += calculate_error(yi,y_pred)\n",
        "      if i%batch == 0 or i==len(X):\n",
        "        velocity = (gamma*velocity) + (learning_rate * dw)\n",
        "        weights -= velocity\n",
        "        #important  \n",
        "        dw = 0\n",
        "    \n",
        "    error /= (2*len(X))\n",
        "\n",
        "    if(epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} :',weights)\n",
        "      print(f'Error after epoch {epoch+1} :',error)\n",
        "\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "weights = np.array([-1,1],dtype='longdouble')\n",
        "\n",
        "momentum_vanilla_gradient_descent(X,y,weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFKtqrbUsAIY",
        "outputId": "d8ac2982-4cd2-42be-ebf7-46cdf0dd6927"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after epoch 50 : [-0.90261693  0.74698767]\n",
            "Error after epoch 50 : [0.13410836]\n",
            "Weights after epoch 100 : [-0.73675606  0.55386541]\n",
            "Error after epoch 100 : [0.13093365]\n",
            "Weights after epoch 150 : [-0.56473959  0.42497552]\n",
            "Error after epoch 150 : [0.1286732]\n",
            "Weights after epoch 200 : [-0.41647069  0.32564855]\n",
            "Error after epoch 200 : [0.12712563]\n",
            "Weights after epoch 250 : [-0.30035394  0.24623578]\n",
            "Error after epoch 250 : [0.12616959]\n",
            "Weights after epoch 300 : [-0.21418839  0.18361179]\n",
            "Error after epoch 300 : [0.1256235]\n",
            "Weights after epoch 350 : [-0.15206796  0.13537449]\n",
            "Error after epoch 350 : [0.12532644]\n",
            "Weights after epoch 400 : [-0.10788571  0.09897339]\n",
            "Error after epoch 400 : [0.12516926]\n",
            "Weights after epoch 450 : [-0.07661391  0.07192456]\n",
            "Error after epoch 450 : [0.12508731]\n",
            "Weights after epoch 500 : [-0.05448972  0.0520454 ]\n",
            "Error after epoch 500 : [0.12504492]\n",
            "Weights after epoch 550 : [-0.03881439  0.03754789]\n",
            "Error after epoch 550 : [0.12502308]\n",
            "Weights after epoch 600 : [-0.02768559  0.02703184]\n",
            "Error after epoch 600 : [0.12501185]\n",
            "Weights after epoch 650 : [-0.01976898  0.01943231]\n",
            "Error after epoch 650 : [0.12500608]\n",
            "Weights after epoch 700 : [-0.01412788  0.01395476]\n",
            "Error after epoch 700 : [0.12500312]\n",
            "Weights after epoch 750 : [-0.01010281  0.01001387]\n",
            "Error after epoch 750 : [0.1250016]\n",
            "Weights after epoch 800 : [-0.00722785  0.00718218]\n",
            "Error after epoch 800 : [0.12500082]\n",
            "Weights after epoch 850 : [-0.00517278  0.00514933]\n",
            "Error after epoch 850 : [0.12500042]\n",
            "Weights after epoch 900 : [-0.00370293  0.0036909 ]\n",
            "Error after epoch 900 : [0.12500022]\n",
            "Weights after epoch 950 : [-0.00265122  0.00264504]\n",
            "Error after epoch 950 : [0.12500011]\n",
            "Weights after epoch 1000 : [-0.00189846  0.00189529]\n",
            "Error after epoch 1000 : [0.12500006]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nesterov Accelerator based GD (Stochastic)"
      ],
      "metadata": {
        "id": "xIwNr6Qmw_On"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict(X,weights,l=1):\n",
        "  result = np.dot(X,weights)\n",
        "  return (1/(1+np.exp(-l * result)))\n",
        "def calculate_derivate(X,y,y_pred):\n",
        "  return ((y_pred - y) * (y_pred) * (1-y_pred) * X)\n",
        "def calculate_error(y,y_pred):\n",
        "  return np.square(y_pred - y)\n",
        "\n",
        "def nesterov_stochastic_gradient_descent(X,y,weights,epochs=500,learning_rate=0.01,gamma = 0.9):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    error = 0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      #important for nesterov\n",
        "      w_lookahead = weights - (gamma * velocity)\n",
        "      y_pred = predict(Xi,w_lookahead)\n",
        "      dw = calculate_derivate(Xi,yi,y_pred)\n",
        "      error += calculate_error(yi,y_pred)\n",
        "\n",
        "      velocity = (gamma*velocity) + (learning_rate * dw)\n",
        "      weights -= velocity \n",
        "\n",
        "    error /= (2*len(X))\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} : ',weights)\n",
        "      print(f'Error after epoch {epoch+1} : ',error) \n",
        "def nesterov_vanilla_gradient_descent(X,y,weights,epochs=500,learning_rate=0.01,gamma = 0.9):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    error = 0\n",
        "    dw = 0\n",
        "    #note the change  lookahead calculated here in vanilla & mini batch \n",
        "    #important for nesterov\n",
        "    w_lookahead = weights - (gamma * velocity)\n",
        "    for Xi,yi in zip(X,y):\n",
        "\n",
        "      y_pred = predict(Xi,w_lookahead)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      error += calculate_error(yi,y_pred)\n",
        "\n",
        "    velocity = (gamma*velocity) + (learning_rate * dw)\n",
        "    weights -= velocity \n",
        "\n",
        "    error /= (2*len(X))\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} : ',weights)\n",
        "      print(f'Error after epoch {epoch+1} : ',error) \n",
        "def nesterov_minibatch_gradient_descent(X,y,weights,epochs=500,learning_rate=0.01,gamma = 0.9,batch=2):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    error = 0\n",
        "    dw = 0\n",
        "    i = 0\n",
        "    #note the change  lookahead calculated here in vanilla & mini batch \n",
        "    #important for nesterov\n",
        "    w_lookahead = weights - (gamma * velocity)\n",
        "    for Xi,yi in zip(X,y):\n",
        "\n",
        "      y_pred = predict(Xi,w_lookahead)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      i+=1\n",
        "      error += calculate_error(yi,y_pred)\n",
        "      \n",
        "      if i%batch == 0 or i == len(X):\n",
        "\n",
        "        velocity = (gamma*velocity) + (learning_rate * dw)\n",
        "        weights -= velocity \n",
        "        dw = 0\n",
        "        w_lookahead = weights - (gamma * velocity)\n",
        "\n",
        "    error /= (2*len(X))\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} : ',weights)\n",
        "      print(f'Error after epoch {epoch+1} : ',error) \n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "weights = np.array([-1,1],dtype='longdouble')\n",
        "\n",
        "nesterov_stochastic_gradient_descent(X,y,weights)"
      ],
      "metadata": {
        "id": "43GU5t4lxKq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69606105-8580-48a1-ebc1-de194c7d9154"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after epoch 50 :  [-0.87678323  0.72832187]\n",
            "Error after epoch 50 :  [0.13373068]\n",
            "Weights after epoch 100 :  [-0.71091533  0.54772924]\n",
            "Error after epoch 100 :  [0.13073888]\n",
            "Weights after epoch 150 :  [-0.54789621  0.42053231]\n",
            "Error after epoch 150 :  [0.12861488]\n",
            "Weights after epoch 200 :  [-0.4089435   0.32267278]\n",
            "Error after epoch 200 :  [0.12717828]\n",
            "Weights after epoch 250 :  [-0.29961063  0.24550554]\n",
            "Error after epoch 250 :  [0.12628666]\n",
            "Weights after epoch 300 :  [-0.21746087  0.18500945]\n",
            "Error after epoch 300 :  [0.12576834]\n",
            "Weights after epoch 350 :  [-0.15726532  0.13824996]\n",
            "Error after epoch 350 :  [0.12547925]\n",
            "Weights after epoch 400 :  [-0.11369221  0.10260813]\n",
            "Error after epoch 400 :  [0.1253219]\n",
            "Weights after epoch 450 :  [-0.08230163  0.07574954]\n",
            "Error after epoch 450 :  [0.12523746]\n",
            "Weights after epoch 500 :  [-0.05970587  0.05568712]\n",
            "Error after epoch 500 :  [0.12519253]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adagrad Mini batch  "
      ],
      "metadata": {
        "id": "uoRo1Ux8ymJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adagrad_minibatch_gd(X,y,weights,epochs=500,learning_rate=0.01,epsilon=1e08,batch=2):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    error = 0\n",
        "    dw = 0\n",
        "    i = 0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      i+= 1\n",
        "      error += calculate_error(yi,y_pred)\n",
        "\n",
        "      if i%batch == 0 or i == len(X):\n",
        "        #note the dofference in vdelocity updation \n",
        "        velocity = velocity + (dw ** 2)\n",
        "        #note change in weight update rule\n",
        "        weights -= ((learning_rate*dw) / (np.sqrt(velocity + epsilon)))\n",
        "        dw = 0\n",
        "    error /= (2 * len(X))\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} : ',weights)\n",
        "      print(f'Error after epoch {epoch+1} : ',error)\n",
        "\n",
        "def adagrad_vanilla_gd(X,y,weights,epochs=500,learning_rate=0.01,epsilon=1e08,batch=2):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    error = 0\n",
        "    dw = 0\n",
        "\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      \n",
        "      error += calculate_error(yi,y_pred)\n",
        "\n",
        "      \n",
        "    #note the dofference in vdelocity updation \n",
        "    velocity = velocity + (dw ** 2)\n",
        "    #note change in weight update rule\n",
        "    weights -= ((learning_rate*dw) / (np.sqrt(velocity + epsilon)))\n",
        "    \n",
        "    error /= (2 * len(X))\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} : ',weights)\n",
        "      print(f'Error after epoch {epoch+1} : ',error)\n",
        "def adagrad_stochastic_gd(X,y,weights,epochs=500,learning_rate=0.01,epsilon=1e08,batch=2):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    error = 0\n",
        "   \n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw = calculate_derivate(Xi,yi,y_pred)\n",
        "      \n",
        "      error += calculate_error(yi,y_pred)\n",
        "\n",
        "      \n",
        "      #note the dofference in vdelocity updation \n",
        "      velocity = velocity + (dw ** 2)\n",
        "      #note change in weight update rule\n",
        "      weights -= ((learning_rate*dw) / (np.sqrt(velocity + epsilon)))\n",
        "    \n",
        "    error /= (2 * len(X))\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} : ',weights)\n",
        "      print(f'Error after epoch {epoch+1} : ',error)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "weights = np.array([-1,1],dtype='longdouble')\n",
        "\n",
        "adagrad_minibatch_gd(X,y,weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NyBvkR1ylbi",
        "outputId": "203eba93-c051-466d-f76d-e1aa53d858ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after epoch 50 :  [-0.99999906  0.99999639]\n",
            "Error after epoch 50 :  [0.13834695]\n",
            "Weights after epoch 100 :  [-0.99999813  0.99999279]\n",
            "Error after epoch 100 :  [0.13834688]\n",
            "Weights after epoch 150 :  [-0.99999719  0.99998918]\n",
            "Error after epoch 150 :  [0.13834681]\n",
            "Weights after epoch 200 :  [-0.99999625  0.99998558]\n",
            "Error after epoch 200 :  [0.13834674]\n",
            "Weights after epoch 250 :  [-0.99999532  0.99998197]\n",
            "Error after epoch 250 :  [0.13834667]\n",
            "Weights after epoch 300 :  [-0.99999438  0.99997836]\n",
            "Error after epoch 300 :  [0.1383466]\n",
            "Weights after epoch 350 :  [-0.99999344  0.99997476]\n",
            "Error after epoch 350 :  [0.13834653]\n",
            "Weights after epoch 400 :  [-0.99999251  0.99997115]\n",
            "Error after epoch 400 :  [0.13834646]\n",
            "Weights after epoch 450 :  [-0.99999157  0.99996755]\n",
            "Error after epoch 450 :  [0.1383464]\n",
            "Weights after epoch 500 :  [-0.99999063  0.99996394]\n",
            "Error after epoch 500 :  [0.13834633]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adam GD "
      ],
      "metadata": {
        "id": "ybmrtSJ41MNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(Xi,weights,l=1):\n",
        "  result = np.dot(Xi,weights)\n",
        "  return (1/(1+np.exp(-l * result)))\n",
        "def calculate_derivate(Xi,yi,y_pred):\n",
        "  return((y_pred-yi) * y_pred * (1-y_pred) * Xi)\n",
        "def calculate_error(yi,y_pred):\n",
        "  return np.square(y_pred - yi)\n",
        "\n",
        "def adam_vanilla_gd(X,y,weights,epochs=500,learning=0.01,epsilon=1e-8,beta1=0.9,beta2=0.999,batch=2):\n",
        "  #new\n",
        "  momentum = 0\n",
        "  velocity =0\n",
        "  for epoch in range(epochs):\n",
        "    dw = 0\n",
        "    error = 0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      error += calculate_error(yi,y_pred)\n",
        "    \n",
        "    #note the additions - momentum and  velocity \n",
        "    momentum = (beta1 * momentum) + ((1-beta1) * dw)\n",
        "    velocity = (beta2 * velocity) + ((1-beta2) * (dw**2))\n",
        "    step = epoch +1\n",
        "    momentum_cap = momentum / (1 - (beta1 ** step))\n",
        "    velocity_cap = velocity / (1- (beta2 ** step))\n",
        "    weights -= ((learning*momentum_cap) / (np.sqrt(velocity_cap + epsilon)))\n",
        "\n",
        "    error /= (2*len(X))\n",
        "\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1}',weights)\n",
        "      print(f'Error after epoch {epoch +1}',error)\n",
        "\n",
        "def adam_stochastic_gd(X,y,weights,epochs=500,learning=0.01,epsilon=1e-8,beta1=0.9,beta2=0.999,batch=2):\n",
        "  #new\n",
        "  momentum = 0\n",
        "  velocity =0\n",
        "  #note in stochastic \n",
        "  step = 0\n",
        "  for epoch in range(epochs):\n",
        "   \n",
        "    error = 0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw = calculate_derivate(Xi,yi,y_pred)\n",
        "      error += calculate_error(yi,y_pred)\n",
        "    \n",
        "      #note the additions - momentum and  velocity \n",
        "      momentum = (beta1 * momentum) + ((1-beta1) * dw)\n",
        "      velocity = (beta2 * velocity) + ((1-beta2) * (dw**2))\n",
        "\n",
        "      #change of step updation in stiochastic \n",
        "      step += 1\n",
        "\n",
        "      momentum_cap = momentum / (1 - (beta1 ** step))\n",
        "      velocity_cap = velocity / (1- (beta2 ** step))\n",
        "      weights -= ((learning*momentum_cap) / (np.sqrt(velocity_cap + epsilon)))\n",
        "\n",
        "    error /= (2*len(X))\n",
        "\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1}',weights)\n",
        "      print(f'Error after epoch {epoch +1}',error)\n",
        "\n",
        "def adam_minibatch_gd(X,y,weights,epochs=500,learning=0.01,epsilon=1e-8,beta1=0.9,beta2=0.999,batch=2):\n",
        "  #new\n",
        "  momentum = 0\n",
        "  velocity =0\n",
        "\n",
        "  #see step initialisation\n",
        "  step = 0\n",
        "  for epoch in range(epochs):\n",
        "    dw = 0\n",
        "    i=0\n",
        "    error = 0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      i+=1\n",
        "      error += calculate_error(yi,y_pred)\n",
        "      if i%batch == 0 or i == len(X):\n",
        "        #note the additions - momentum and  velocity \n",
        "        momentum = (beta1 * momentum) + ((1-beta1) * dw)\n",
        "        velocity = (beta2 * velocity) + ((1-beta2) * (dw**2))\n",
        "\n",
        "        #note change in step updation \n",
        "        step +=1\n",
        "        momentum_cap = momentum / (1 - (beta1 ** step))\n",
        "        velocity_cap = velocity / (1- (beta2 ** step))\n",
        "        weights -= ((learning*momentum_cap) / (np.sqrt(velocity_cap + epsilon)))\n",
        "        #important \n",
        "        dw = 0\n",
        "        \n",
        "    error /= (2*len(X))\n",
        "\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1}',weights)\n",
        "      print(f'Error after epoch {epoch +1}',error)\n",
        "def adam_vanilla_gd(X,y,weights,epochs=500,learning=0.01,epsilon=1e-8,beta1=0.9,beta2=0.999,batch=2):\n",
        "  #new\n",
        "  momentum = 0\n",
        "  velocity =0\n",
        "  for epoch in range(epochs):\n",
        "    dw = 0\n",
        "    error = 0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      error += calculate_error(yi,y_pred)\n",
        "    \n",
        "    #note the additions - momentum and  velocity \n",
        "    momentum = (beta1 * momentum) + ((1-beta1) * dw)\n",
        "    velocity = (beta2 * velocity) + ((1-beta2) * (dw**2))\n",
        "    step = epoch +1\n",
        "    momentum_cap = momentum / (1 - (beta1 ** step))\n",
        "    velocity_cap = velocity / (1- (beta2 ** step))\n",
        "    weights -= ((learning*momentum_cap) / (np.sqrt(velocity_cap + epsilon)))\n",
        "\n",
        "    error /= (2*len(X))\n",
        "\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1}',weights)\n",
        "      print(f'Error after epoch {epoch +1}',error)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "weights = np.array([-1,1],dtype=\"longdouble\")\n",
        "adam_vanilla_gd(X,y,weights)\n"
      ],
      "metadata": {
        "id": "IwQR8_Ikr-RX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c250b36-cdca-44d7-a276-204f4f7efed9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after epoch 50 [-0.4926079   0.53320742]\n",
            "Error after epoch 50 [0.12916512]\n",
            "Weights after epoch 100 [-0.14472774  0.2050715 ]\n",
            "Error after epoch 100 [0.12555797]\n",
            "Weights after epoch 150 [-0.03469891  0.05103675]\n",
            "Error after epoch 150 [0.12503417]\n",
            "Weights after epoch 200 [-0.00547008  0.00820874]\n",
            "Error after epoch 200 [0.12500089]\n",
            "Weights after epoch 250 [-0.00046226  0.0006961 ]\n",
            "Error after epoch 250 [0.12500001]\n",
            "Weights after epoch 300 [-2.06306744e-06  3.22643532e-06]\n",
            "Error after epoch 300 [0.125]\n",
            "Weights after epoch 350 [ 2.21052128e-06 -3.31254379e-06]\n",
            "Error after epoch 350 [0.125]\n",
            "Weights after epoch 400 [-2.41936542e-08  3.66464901e-08]\n",
            "Error after epoch 400 [0.125]\n",
            "Weights after epoch 450 [-9.20831215e-09  1.38565973e-08]\n",
            "Error after epoch 450 [0.125]\n",
            "Weights after epoch 500 [ 7.34862879e-10 -1.09914563e-09]\n",
            "Error after epoch 500 [0.125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RMS Prop"
      ],
      "metadata": {
        "id": "EooM-lj31ga2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rms_vanilla_gd(X,y,weights,epochs=500,learning_rate=0.01,epsilon=1e-8,beta=0.5,batch=2):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    error = 0\n",
        "    dw = 0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      error += calculate_error(yi,y_pred)\n",
        "    \n",
        "    #note this change in velocity update \n",
        "    velocity = (beta * velocity) + ((1-beta) * (dw**2))\n",
        "    #note this weight update similar to adagrad  \n",
        "    weights -= ((learning_rate * dw) / (np.sqrt(velocity + epsilon)))\n",
        "    error /= (2*len(X))\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} : ',weights)\n",
        "      print(f'Error after epoch {epoch+1} : ',error)\n",
        "def rms_stochastic_gd(X,y,weights,epochs=500,learning_rate=0.01,epsilon=1e-8,beta=0.5,batch=2):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    error = 0\n",
        "    \n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw = calculate_derivate(Xi,yi,y_pred)\n",
        "      error += calculate_error(yi,y_pred)\n",
        "    \n",
        "    #note this change in velocity update \n",
        "      velocity = (beta * velocity) + ((1-beta) * (dw**2))\n",
        "      #note this weight update similar to adagrad  \n",
        "      weights -= ((learning_rate * dw) / (np.sqrt(velocity + epsilon)))\n",
        "    error /= (2*len(X))\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} : ',weights)\n",
        "      print(f'Error after epoch {epoch+1} : ',error)\n",
        "def rms_minibatch_gd(X,y,weights,epochs=500,learning_rate=0.01,epsilon=1e-8,beta=0.5,batch=2):\n",
        "  velocity = 0\n",
        "  for epoch in range(epochs):\n",
        "    error = 0\n",
        "    dw = 0\n",
        "    i=0\n",
        "    for Xi,yi in zip(X,y):\n",
        "      y_pred = predict(Xi,weights)\n",
        "      dw += calculate_derivate(Xi,yi,y_pred)\n",
        "      i+=1\n",
        "      error += calculate_error(yi,y_pred)\n",
        "      if i%batch == 0 or i==len(X):\n",
        "\n",
        "\n",
        "        #note this change in velocity update \n",
        "        velocity = (beta * velocity) + ((1-beta) * (dw**2))\n",
        "        #note this weight update similar to adagrad  \n",
        "        weights -= ((learning_rate * dw) / (np.sqrt(velocity + epsilon)))\n",
        "        dw = 0\n",
        "        \n",
        "    error /= (2*len(X))\n",
        "    if (epoch+1)%50 == 0:\n",
        "      print(f'Weights after epoch {epoch+1} : ',weights)\n",
        "      print(f'Error after epoch {epoch+1} : ',error)\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "weights = np.array([-1,1],dtype='longdouble')\n",
        "\n",
        "rms_vanilla_gd(X,y,weights)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QmvdA6j1kW7",
        "outputId": "d359d2a9-3d40-4c87-fcc2-3c839c4bf8bd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after epoch 50 :  [-0.49195468  0.49939579]\n",
            "Error after epoch 50 :  [0.12884365]\n",
            "Weights after epoch 100 :  [-0.02077174  0.02681676]\n",
            "Error after epoch 100 :  [0.12501587]\n",
            "Weights after epoch 150 :  [-0.00495911 -0.00495911]\n",
            "Error after epoch 150 :  [0.12500116]\n",
            "Weights after epoch 200 :  [-0.00495911 -0.00495911]\n",
            "Error after epoch 200 :  [0.12500116]\n",
            "Weights after epoch 250 :  [-0.00495911 -0.00495911]\n",
            "Error after epoch 250 :  [0.12500116]\n",
            "Weights after epoch 300 :  [-0.00495911 -0.00495911]\n",
            "Error after epoch 300 :  [0.12500116]\n",
            "Weights after epoch 350 :  [-0.00495911 -0.00495911]\n",
            "Error after epoch 350 :  [0.12500116]\n",
            "Weights after epoch 400 :  [-0.00495911 -0.00495911]\n",
            "Error after epoch 400 :  [0.12500116]\n",
            "Weights after epoch 450 :  [-0.00495911 -0.00495911]\n",
            "Error after epoch 450 :  [0.12500116]\n",
            "Weights after epoch 500 :  [-0.00495911 -0.00495911]\n",
            "Error after epoch 500 :  [0.12500116]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Max Pooling "
      ],
      "metadata": {
        "id": "YxpLTxih8Kui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def pool(matrix,stride,pool_size):\n",
        "  paddedMatrix = np.array([[0]*paddedMatrix_width for i in range(paddedMatrix_height)])\n",
        "  height = len(matrix)\n",
        "  width = len(matrix[0])\n",
        "  i = 0\n",
        "  j = 0\n",
        "  oi = 0\n",
        "  oj = 0\n",
        "\n",
        "  while(i + pool_size <= height):\n",
        "    while(j + pool_size <= width):\n",
        "      pool_window =[] \n",
        "\n",
        "      for h in range(pool_size):\n",
        "        for w in range(pool_size):\n",
        "          pool_window.append(matrix[i+h][j+w])\n",
        "      \n",
        "      paddedMatrix[oi][oj] = max(pool_window)\n",
        "      oj += 1\n",
        "      j = j+stride \n",
        "    i  = i+stride\n",
        "    oi += 1\n",
        "    j=0\n",
        "    oj = 0\n",
        "  return paddedMatrix\n",
        "print(\"Creating Original Matrix \")\n",
        "\n",
        "og_height = int(input(\"Enter the height of matrix\"))\n",
        "og_width = int(input(\"Enter the width of matrix\"))\n",
        "matrix = [[0]*og_width for i in range(og_height)]\n",
        "\n",
        "for i in range(og_height):\n",
        "  for j in range(og_width):\n",
        "    matrix[i][j] = int(input(f'Enter the values of matrix[{i}][{j}] :'))\n",
        "\n",
        "pad_amt = int(input(\"enter the amount of padding\"))\n",
        "pad_val = int(input(\"Enter the padding value\"))\n",
        "stride = int(input(\"enter the amount of stride\"))\n",
        "pool_size = int(input(\"enter the pool size \"))\n",
        "\n",
        "paddedMatrix_width = ((og_width + (2*pad_amt) - pool_size)//stride) + 1\n",
        "paddedMatrix_height = ((og_height + (2*pad_amt) - pool_size)//stride) + 1\n",
        "\n",
        "matrix = np.array(matrix)\n",
        "print()\n",
        "\n",
        "print(\"Input Matrix : \")\n",
        "print(matrix)\n",
        "print()\n",
        "\n",
        "matrix = np.pad(matrix,pad_amt,constant_values=pad_val)\n",
        "print(\"After Padding : \")\n",
        "print(matrix)\n",
        "print()\n",
        "83\n",
        "matrix = pool(matrix,stride,pool_size)\n",
        "print('After Pooling :- ')\n",
        "print(matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALyX1pwI8PgB",
        "outputId": "6b850b40-6ee3-4a04-addb-998a3cfe4f06"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Original Matrix \n",
            "Enter the height of matrix3\n",
            "Enter the width of matrix3\n",
            "Enter the values of matrix[0][0] :2\n",
            "Enter the values of matrix[0][1] :3\n",
            "Enter the values of matrix[0][2] :4\n",
            "Enter the values of matrix[1][0] :5\n",
            "Enter the values of matrix[1][1] :6\n",
            "Enter the values of matrix[1][2] :7\n",
            "Enter the values of matrix[2][0] :8\n",
            "Enter the values of matrix[2][1] :9\n",
            "Enter the values of matrix[2][2] :2\n",
            "enter the amount of padding2\n",
            "Enter the padding value0\n",
            "enter the amount of stride2\n",
            "enter the pool size 2\n",
            "\n",
            "Input Matrix : \n",
            "[[2 3 4]\n",
            " [5 6 7]\n",
            " [8 9 2]]\n",
            "\n",
            "After Padding : \n",
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 2 3 4 0 0]\n",
            " [0 0 5 6 7 0 0]\n",
            " [0 0 8 9 2 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "\n",
            "After P5ooling :- \n",
            "[[0 0 0]\n",
            " [0 6 7]\n",
            " [0 9 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Convolution"
      ],
      "metadata": {
        "id": "CRXMX61tEwmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolve(matrix,filter,stride):\n",
        "  op_matrix = np.array([[0]*filteredMatrix_width for i in range(filteredMatrix_height)])\n",
        "\n",
        "  height = len(matrix)\n",
        "  width = len(matrix[0])\n",
        "\n",
        "  i=0\n",
        "  j=0\n",
        "  oi = 0\n",
        "  oj = 0\n",
        "\n",
        "  while(i+filter_height <= height):\n",
        "    while(j+filter_width <= width):\n",
        "      window = []\n",
        "      for h in range(filter_height):\n",
        "        for w in range(filter_width):\n",
        "          window.append(matrix[i+h][j+w])\n",
        "      \n",
        "      op_matrix[oi][oj] = np.dot(np.array(window),filter.ravel())\n",
        "      oj += 1\n",
        "      j = j+stride\n",
        "    i = i+stride\n",
        "    oi += 1\n",
        "    j= 0\n",
        "    oj =0\n",
        "  return op_matrix\n",
        "\n",
        "og_height = int(input(\"Enter the height of matrix\"))\n",
        "og_width = int(input(\"Enter the width of matrix\"))\n",
        "matrix = [[0]*og_width for i in range(og_height)]\n",
        "\n",
        "for i in range(og_height):\n",
        "  for j in range(og_width):\n",
        "    matrix[i][j] = int(input(f'Enter the values of matrix[{i}][{j}] :'))\n",
        "\n",
        "\n",
        "filter_height = int(input(\"Filter Height\"))\n",
        "filter_width = int(input(\"Filter Width\"))\n",
        "\n",
        "filter = [[0]* filter_width for i in range(filter_height)]\n",
        "\n",
        "for i in range(filter_height):\n",
        "  for j in range(filter_width):\n",
        "    filter[i][j] = int(input(f'Enter value of filter[{i}][{j}] : '))\n",
        "\n",
        "pad_amt = int(input(\"enter the amount of padding\"))\n",
        "pad_val = int(input(\"Enter the padding value\"))\n",
        "stride = int(input(\"enter the amount of stride\"))\n",
        "\n",
        "\n",
        "filteredMatrix_width = ((og_width + (2*pad_amt) - filter_width)//stride) + 1\n",
        "filteredMatrix_height = ((og_height + (2*pad_amt) - filter_height)//stride) + 1\n",
        "\n",
        "filter = np.array(filter)\n",
        "matrix = np.array(matrix)\n",
        "\n",
        "print(\"Input matrix\") \n",
        "print(matrix)\n",
        "print()\n",
        "print(\"Filter : \")\n",
        "print(filter)\n",
        "print()\n",
        "matrix = np.pad(matrix,pad_amt,constant_values=pad_val)\n",
        "print(\"After Padding : \")\n",
        "print(matrix)\n",
        "print()\n",
        "filteredOp = convolve(matrix,filter,stride)\n",
        "print(\"After Filter \")\n",
        "print(filteredOp)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUzcQ32cEzJh",
        "outputId": "30a2ac9c-f585-48ce-aa45-a7b17ac9d6c1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the height of matrix3\n",
            "Enter the width of matrix3\n",
            "Enter the values of matrix[0][0] :2\n",
            "Enter the values of matrix[0][1] :3\n",
            "Enter the values of matrix[0][2] :4\n",
            "Enter the values of matrix[1][0] :5\n",
            "Enter the values of matrix[1][1] :6\n",
            "Enter the values of matrix[1][2] :7\n",
            "Enter the values of matrix[2][0] :8\n",
            "Enter the values of matrix[2][1] :9\n",
            "Enter the values of matrix[2][2] :2\n",
            "Filter Height2\n",
            "Filter Width2\n",
            "Enter value of filter[0][0] : 2\n",
            "Enter value of filter[0][1] : 2\n",
            "Enter value of filter[1][0] : 2\n",
            "Enter value of filter[1][1] : 2\n",
            "enter the amount of padding2\n",
            "Enter the padding value0\n",
            "enter the amount of stride2\n",
            "Input matrix\n",
            "[[2 3 4]\n",
            " [5 6 7]\n",
            " [8 9 2]]\n",
            "\n",
            "Filter : \n",
            "[[2 2]\n",
            " [2 2]]\n",
            "\n",
            "After Padding : \n",
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 2 3 4 0 0]\n",
            " [0 0 5 6 7 0 0]\n",
            " [0 0 8 9 2 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "After Filter \n",
            "[[ 0  0  0]\n",
            " [ 0 32 22]\n",
            " [ 0 34  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TDt1po5b-9He"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}